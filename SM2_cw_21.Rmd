---
title: "Statistical Modelling 2"
output:
     pdf_document:
         latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
load("01400919.RData")
```


### 1. Exploratory Data Analysis

```{r}
library(knitr)
dat <- data.frame(read$attention, read$fluency, read$yr, read$count)
str(dat)
colnames(dat)[1] <- "attention"
colnames(dat)[2] <- "fluency"
colnames(dat)[3] <- "year"
colnames(dat)[4] <- "count"
#dat$year <- as.integer(dat$year)
kable(head(dat))
```

```{r}
summary(dat)
```

```{r}
library(skimr)
skim(dat)
with(dat, table(count))
```

```{r}
library(DataExplorer)
plot_histogram(dat)
```
```{r}
plot_boxplot(dat, by= "count")
print(dat$year)
```
```{r}
pairs(dat,cex.labels=0.95)
```


### 2. Fit initial model suggested by the team (using attention and verbal fluency only)

```{r}
fit0 <- lm(count~attention+fluency, data=dat)

# plot linear model
summary(fit0)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1))
plot(fit0)
```

```{r}
# remove potential outliers and fit model again
dat1 <- dat[c(-127,-150,-167),] 
fit01 <- lm(count~attention+fluency, data=dat1)

# summary and diagnostic plots of model without potential outliers
summary(fit01)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit01)
```
```{r}
AIC(fit0)
AIC(fit01)
```


### 3. Fit alternative Poisson GLM with log link model + evaluate quality of fit

```{r}
# response variable and predictors for Poisson GLM
y <- as.numeric(dat$count)
x1 <- cbind(as.numeric(dat$attention), as.numeric(dat$fluency))
X <- cbind(1,x1)
```

```{r}
# IWLS
# find initial estimate for beta
fit1 <- lm(y~x1)
beta <- fit1$coefficients 

# inverse link function
log.link <- function(u){
  exp(u)
}

# deviance function
D <- function(p){ # p is the estimated mean mu
  a <- y*log(y/p)
  b <- (p-y)
  a[y==0] <- 0
  2*sum(a+b)
}

oldD <- D(log.link(as.numeric(X%*%beta)))
jj <- 0
while(jj==0){
  eta <- X%*%beta # estimated linear predictor
  mu <- log.link(eta) # estimated mean response
  z <- eta + ((y-mu)/mu) # form the adjusted variate
  w <- mu # weights
  lmod <- lm(z~x1, weights=w) # regress z on x with weights w, includes intercept anyway
  beta <- as.vector(lmod$coeff) # newbeta
  newD <- D(log.link(X%*%beta))
  control <- abs(newD-oldD)/(abs(newD)+0.1)
  if(control<1e-8)
    jj <- 1
  oldD <- newD
}
beta # final estimate

```

```{r}
newD # last deviance calculated
```

```{r}
# Results from IWLS Poisson

# Pearson's statistic
X2 <- 0
for (i in 1:185){
  X2 <- X2 + (y[i]-mu[i])^2/w[i]
}

# dispersion parameter estimate
phi <- X2/(185-3) #n-p, n number of rows, p number of predictors
phi

# computation of covariance matrix and standard residuals for estimates
J <- t(X)%*%diag(as.vector(w))%*%X
invJ <- solve(J)
cov.beta <- phi*invJ
beta.sd <- sqrt(as.vector(diag(cov.beta)))
beta.sd
```

```{r}
# computation of deviance residuals
p <- as.vector(log.link(X%*%beta))
a <- y*log(y/p)
b <- (y-p)
a[y==0] <- 0 
d <- sign(y-mu)*sqrt(2*(a+b))
summary(d)
```

```{r}
z <- beta/beta.sd
z # large n makes the student t distribution tend to normal distribution
```

```{r}
# sanity check
fit10 <- glm(count~attention+fluency, family="poisson", data=dat)
summary(fit10)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit10)
```

```{r}
confint(fit10)
```


```{r}
# remove potential outliers
dat2 <- dat[-c(167,127,150),]
fit11 <-  glm(count~attention+fluency, family="poisson", data=dat2)

# model without potential outliers
summary(fit11)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit11)
```

```{r}
AIC(fit10)
AIC(fit11)
```

```{r}
# use step search to compare models 
fit12 <- glm(count~attention+fluency+year, family="poisson", data=dat)
stepsearch <- step(fit12,~.^2,test="Chisq")
stepsearch$anova
```
```{r}
summary(stepsearch)
```

```{r}
fit13 <- glm(formula = count ~ attention + fluency + year + attention:year + 
    attention:fluency + fluency:year, family = "poisson", data = dat)
summary(fit13)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit13)
```

```{r}
residuals(stepsearch, type="pearson")
residuals(stepsearch, type="deviance")
```

```{r}
cooks.distance(stepsearch)
```

```{r}
rstandard(stepsearch, type="pearson")
rstandard(stepsearch, type="deviance")
par(mfrow=c(1,2))
plot(abs(rstandard(stepsearch, type="pearson")), xlab="Index", ylab="Std. Pearson's residual", pch=16)
plot(influence(stepsearch)$hat, xlab="Index", ylab="Leverage", pch=16)
l_threshold <- 2*8 / 185
l_threshold
abline(h=l_threshold, col="red")
```
```{r}
order(abs(rstandard(stepsearch, type="pearson")), decreasing = TRUE)[1:5]
order(influence(stepsearch)$hat, decreasing=TRUE)[1:5]
```

There is no reoccuring indices.

### 4. Fit own models + evaluate quality of fit

```{r}
# fit defined model, try a few
require(MASS)

lin <- glm(count~attention+fluency+year, data=dat)
pois <- glm(count~attention+fluency+year, family= poisson, data=dat)
qpois <- glm(count~attention+fluency+year, family= quasipoisson, data=dat)
nbin <- glm.nb(count~attention+fluency+year, data=dat)
```

```{r}
summary(lin)
list(residual.deviance           = deviance(lin),
     residual.degrees.of.freedom = df.residual(lin),
     chisq.p.value               = pchisq(deviance(lin), df.residual(lin), lower = F)
     )
```

```{r}
summary(pois)
list(residual.deviance           = deviance(pois),
     residual.degrees.of.freedom = df.residual(pois),
     chisq.p.value               = pchisq(deviance(pois), df.residual(pois), lower = F)
     )
```

```{r}
summary(qpois)
list(residual.deviance           = deviance(pois),
     residual.degrees.of.freedom = df.residual(pois),
     chisq.p.value               = pchisq(deviance(pois), df.residual(pois), lower = F)
     )
```

```{r}
summary(nbin)
list(residual.deviance           = deviance(nbin),
     residual.degrees.of.freedom = df.residual(nbin),
     chisq.p.value               = pchisq(deviance(nbin), df.residual(nbin), lower = F)
     )
```

From now, on let's use the negbinomial model:

```{r}
# response variable and predictors for NegBin GLM
y <- as.numeric(dat$count)
x2 <- cbind(as.numeric(dat$attention), as.numeric(dat$year))
X2 <- cbind(1,x2)
```

```{r}
# IWLS
# find initial beta
fit3 <- lm(y~x2)
beta <- fit3$coefficients

# inverse link function
log.link <- function(u){
  exp(u)
}

# deviance function
D <- function(p){ # p is the estimated mean mu
  a <- y*log(y/p)
  b <- (3+y)*log((p+3)/(y+3))
  a[y==0] <- 0
  2*sum(a+b)
}

oldD <- D(log.link(as.numeric(X2%*%beta)))
jj <- 0
while(jj==0){
  eta <- X2%*%beta # estimated linear predictor
  mu <- log.link(eta) # estimated mean response
  z <- eta + ((y-mu)/mu) # form the adjusted variate
  w <- 3*mu/(mu+3) # weights
  lmod <- lm(z~x2, weights=w) # regress z on x with weights w, includes intercept anyway
  beta <- as.vector(lmod$coeff) # newbeta
  newD <- D(log.link(X2%*%beta))
  control <- abs(newD-oldD)/(abs(newD)+0.1)
  if(control<1e-8)
    jj <- 1
  oldD <- newD
}
beta # final estimate

```

```{r}
newD # last deviance calculated
```

```{r}
# Diagnostics

# Pearson's statistic for negbin
X3 <- 0
for (i in 1:185){
  X3 <- X3 + (y[i]-mu[i])^2/(mu[i]*(mu[i]+3)/3)
}

# dispersion parameter estimate
phi <- X3/(185-3) #n-p, n number of rows, p number of predictors
phi 

# computation of covariance matrix and standard residuals for estimates
J <- t(X2)%*%diag(as.vector(w))%*%X2
invJ <- solve(J)
cov.beta <- phi*invJ
beta.sd <- sqrt(as.vector(diag(cov.beta)))
beta.sd
```

```{r}
# confidence intervals for estimates of model parameters
beta1.CI = c(beta[1]-qt(0.975, 182)*beta.sd[1],beta[1]+qt(0.975, 182)*beta.sd[1])
beta1.CI
beta2.CI = c(beta[2]-qt(0.975, 182)*beta.sd[2],beta[2]+qt(0.975, 182)*beta.sd[2])
beta2.CI
beta3.CI = c(beta[3]-qt(0.975, 182)*beta.sd[3],beta[3]+qt(0.975, 182)*beta.sd[3])
beta3.CI
```

```{r}
# sanity check
fit30 <- glm.nb(count~attention+year, data=dat)
```

```{r}
# summary and plots of sanity check
summary(fit30)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit30)
```

```{r}
# spotting potential outliers
dat2 <- dat[-c(12,167,127),]
fit31 <- glm.nb(count~attention+year, data=dat)

# summary and diagnostic plots without suspicious points
summary(fit31)
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit31)
```

```{r}
# computation of deviance residuals
a <- y*log(y/p)
b <- (3+y)*log((p+3)/(y+3))
a[y==0] <- 0
d <- sign(y-mu)*sqrt(2*(a+b))
summary(d)
```

```{r}
z <- beta/beta.sd
z # large n makes the student t distribution tend to normal distribution
```


```{r}
# use step search to compare models 
fit32 <- glm.nb(count~attention+fluency+year, data=dat)
stepsearch <- step(fit32,~.^2,test="Chisq")
stepsearch$anova
```

```{r}
summary(stepsearch)
```

```{r}
fit33 <- glm.nb(formula = count ~ attention + year + attention:year + 
    fluency:year, data = dat, init.theta = 3.388864932, 
    link = log)
summary(fit33)
```

```{r}
par(mfrow = c(2, 2), mar = c(4.3, 4.3, 2, 1.2))
plot(fit33)
```

```{r}
#Confidence interval:
confint(fit33)
```

```{r}
residuals(stepsearch, type="pearson")
residuals(stepsearch, type="deviance")
```

```{r}
cooks.distance(stepsearch)
```

```{r}
rstandard(stepsearch, type="pearson")
rstandard(stepsearch, type="deviance")
par(mfrow=c(1,2))
plot(abs(rstandard(stepsearch, type="pearson")), xlab="Index", ylab="Std. Pearson's residual", pch=16)
plot(influence(stepsearch)$hat, xlab="Index", ylab="Leverage", pch=16)
l_threshold <- 2*8 / 185
l_threshold
abline(h=l_threshold, col="red")
```

```{r}
order(abs(rstandard(stepsearch, type="pearson")), decreasing = TRUE)[1:5]
order(influence(stepsearch)$hat, decreasing=TRUE)[1:5]
```


### 5. Analysis of best model

- estimates of model parameters
- confidence intervals
- limitations
- experimental design